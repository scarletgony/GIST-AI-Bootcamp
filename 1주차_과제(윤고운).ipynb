{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1주차 과제.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPY1huRLmw0782Lyogp6KFG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/scarletgony/GIST-AI-Bootcamp/blob/master/1%EC%A3%BC%EC%B0%A8_%EA%B3%BC%EC%A0%9C(%EC%9C%A4%EA%B3%A0%EC%9A%B4).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzn6O4wMJtqI",
        "colab_type": "text"
      },
      "source": [
        "#**인공지능 활용사례**\n",
        "\n",
        "###1. 사물 감별사 **구글 렌즈 (_Google Lens_)**\n",
        "![구글렌즈](https://windowsbulletin.com/wp-content/uploads/2020/02/Google-Lens.jpeg)\n",
        "\n",
        "‘구글 I/O 2017’ 기조연설에서 순다 피아치 구글 CEO가 ‘구글 렌즈’를 소개했다. 구글 렌즈는 인공지능 컴퓨팅 능력으로 **이미지 기반 정보를 습득한다.** 사물을 보이면 이를 이해하고 정보를 전달한다. 카메라에 꽃을 찍으면 무슨 꽃인지 알려주고, 가게를 찍으면 연동된 가게의 정보가 뜬다. 구글은 구글 렌즈 기능을 구글 어시스턴트와 구글 포토에 우선 도입할 예정이다. 점차 다른 제품에도 적용할 계획이라고 했지만 정확한 서비스 제공 시기는 아직 명확하지 않다.\n",
        "\n",
        "###2. 반려동물 장난감 **고미랩스(_LENOVO LECOO UNMANNED STORE_)** \n",
        "![고미볼](https://blog.rocketpunch.com/wp-content/uploads/2019/06/02-1-1024x530.png)\n",
        "\n",
        "인공지능 기반 반려동물 케어 플랫폼 ‘고미랩스’는 반려동물 장난감에 인공지능 기술을 적용했다. 인공지능 **자율주행 장난감 ‘고미’**는 바닥에 두기만 하면 알아서 움직인다. 자이로센서가 내장돼 반려동물의 움직임도 파악한다. 반려동물과 상호작용을 하며 놀이패턴, 견종, 나이, 성별 등을 분석, 어떻게 얼마나 움직이는지부터 건강은 어떤지 데이터를 분석해 앱으로 알려준다.\n",
        "\n",
        "###3. 두려움에 떠는 난민에게 심리치료를 **카림(_Karim_)** \n",
        "![카림](https://scontent-ssn1-1.xx.fbcdn.net/v/t1.0-9/29543280_2141932225831842_1012458604077211480_n.png?_nc_cat=105&_nc_sid=dd9801&_nc_ohc=Z4Dh1JXAabIAX9Bu5dv&_nc_ht=scontent-ssn1-1.xx&oh=cfe60348dd295ca6fcf1254c8142c640&oe=5EF8FA8A)\n",
        "\n",
        "실리콘밸리 스타트업 ‘X2AI’는 심각한 정신적 고통을 겪는 난민을 도우려고 인공지능을 적용한 챗봇 ‘카림’을 개발했다. 카림은 **자연어 처리 기술을 활용**하고 상호작용을 통해 이용자 감정 상태를 지속해서 추적한다. X2AI는 이런 감정을 수치화해 알고리즘화하고 분석된 자료를 바탕으로 난민의 고민에 적절한 질문을 던지고 답변을 준다. 질문에는 취미와 같은 가벼운 것부터 시작해 깊은 감정을 입력할 수 있는 것까지 다양하게 구성된다. X2AI는 NGO와 ‘필드이노베이션팀(FIT)’을 꾸려 카림을 더 많은 난민 심리치료에 사용할 예정이다.\n",
        "\n",
        "###3. 주변의 모든 소리를 따라하는 **라이어버드(_Lyrebird_)** \n",
        "![라이어버드](https://www.valuewalk.com/wp-content/uploads/2018/07/FireShot-Capture-274-Lyrebird-%E2%80%A2-Ultra-Realistic-Voice-Cloning-and-Text-to-_-https___lyrebird.ai_.png)\n",
        "\n",
        "캐나다 몬트리올 스타트업 라이어버드는 사람 목소리를 재현하는 데 인공지능 기술을 사용했다. 필요한 것은 단 60초 정도의 음성 녹음 데이터다. 어도비의 ‘프로젝트 보코’, 구글 딥마인드의 ‘웨이브넷’도 **음성 모방 기술**을 선보인 바 있다. 그러나 프로젝트 보코의 경우 최소 20분 정도의 샘플이 있어야 알고리즘을 만들 수 있다. 라이어버드의 알고리즘은 수십초짜리 음성 데이터만 있다면 0.5초 안에 문장 1천개를 생성할 수 있다. 이 알고리즘은 몬트리올대학 몬트리올학습알고리즘연구소(MILA)에서 개발한 딥러닝 모델을 기반으로 한다. 심지어 감정을 담은 목소리까지 재현할 수 있다. 재현 수준이 완벽한 것은 아니나 연구팀은 몇 년 안에 진짜 목소리와 구별할 수 없는 수준에 이를 수 있다고 말한다. 한편에서는 목소리 재현 알고리즘이 더 정교해지면 이를 악용한 범죄가 발생할 수도 있다고 염려한다."
      ]
    }
  ]
}